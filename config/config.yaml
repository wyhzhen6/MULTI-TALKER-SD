
seed: 1234

# speaker logging
iteration: 30000  
max_choose: 7        # max number of each speaker to choose 
stop_available: 10    # stop if the number of available speakers is less than this value
max_examples: 30000      # max number of examples

speaker:
  # number: ['1-5:0.1', '6-10:0.2', '11-20:0.5', '21-30:0.2']
  number: ['11-20:0.7', '21-30:0.3']
  gender: ['1:0.15', '0:0.15', '0.5:0.233', '0.4:0.233', '0.6:0.233']   # default 'Male ratio : situation ratio'
  language: ['1:0.33', '0:0.33', 'unif:0.33']                           # default 'English ratio : situation ratio'

utterance: '150-250:unif'
meeting:   
  # Normalize the sampling probability using `type_weight` of all types
  # such as: presentation(0.5), discussion(0.3):
  #   For a sample, there is a probability of 0.5/(0.3+0.5)=0.625 that it is set to type p
  discussion:
    type_weight: 0.5
    interval_ratio: [0.4, 0.5, 0.07, 0.03]   # silence, overlap(2 speaker), overlap(3 speaker), overlap(4 speaker)
    silence: '1.5-0.5:norm'                      # Gaussian distribution with a mean of 3s and a standard deviation of 2s
    # or silence: '0.10-0.30:unif'   # 5%-15%
    overlap:  
      2: '0.5-3:unif'         # 0.5s - 3s 
      3: '0.5-1:unif'         # 0.5s - 1s
      4: '0.5-0.8:unif'       # 0.5s - 0.8s

  
  presentation:
    type_weight: 0.5
    main_speaker: '0.2-0.3:0.6-0.7'
    main_speaker_shuffle: 0.1
    interval_ratio: [0.8, 0.2]   # silence, overlap(2 speaker), overlap(3 speaker), overlap(4 speaker)
    silence: '1-0.5:norm'        # Gaussian distribution with a mean of 3s and a standard deviation of 2s
    overlap:  
      2: '0.5-1:unif'         # 0.5s - 1s 
  
  interview:
    type_weight: 0.5
    interviewer_ratio: '0.15-0.2'
    interval_ratio: [0.8, 0.2]  
    silence: '1-0.5:norm'        
    overlap:  
      2: '0.5-1:unif'         # 0.5s - 1s 
    

vad_pretrained_model: 'cache/pyannote-vad/pytorch_model.bin'
whisper_model: 'large-v2'
whisper_model_path: 'cache/whisper_model/'
cutting_max_length: 1.5   # (s) max length of each cutting segment


simulate_config:
  point_noise_csv: "config/noise/noise.csv"
  point_noise_type: "config/noise/point_noise.txt"
  fs: 16000 
  rt60:  null
  rt60_mid:  [0.3, 0.8]   # min, max rt60 of middle room
  rt60_lar:  [0.3, 1]     # min, max rt60 of large room
  max_order: null
  room_size:  null
  room_size_mid:  [[8,7,4], [10,8,5]]  # min, max size of middle room(speaker < 20)
  room_size_lar:  [[10,8,4], [12,10,5]]  # min, max size of large room(speaker >= 20)
  room_type:  null    # middle, large
  meeting_type:  null   # desk, circle, speech
  mic_pos: null   # default: middle of the room, height:desk(0.8m-1m) or ceiling
  host_label: null  # set moving host of speech scene
  signal_gains: [1,5] # min, max gain for src_signal
  SNR_point : null
  SNR_point_arr : [5,10]  # min, max snr of point noise
  SNR_diffuse: null
  SNR_diffuse_arr: [6,10]  # min, max snr of diffuse noise
  is_compute_DRR: false   # if compute DRR
  is_compute_SRR: false   # if compute SRR

