
seed: 1234

# speaker logging
iteration: 30000  
max_choose: 7        # max number of each speaker to choose 
stop_available: 10    # stop if the number of available speakers is less than this value
max_examples: 30000      # max number of examples

speaker:
  # number: ['1-5:0.1', '6-10:0.2', '11-20:0.5', '21-30:0.2']
  number: ['11-20:0.7', '21-30:0.3']
  gender: ['1:0.15', '0:0.15', '0.5:0.233', '0.4:0.233', '0.6:0.233']   # default 'Male ratio : situation ratio'
  language: ['1:0.3', '0:0.3', '0.8:0.2', '0.2:0.2']                           # default 'English ratio : situation ratio'


utterance: '150-250:unif'
meeting:   
  # Normalize the sampling probability using `type_weight` of all types
  # such as: presentation(0.5), discussion(0.3):
  #   For a sample, there is a probability of 0.5/(0.3+0.5)=0.625 that it is set to type p
  discussion:
    type_weight: 0.5
    interval_ratio: [0.3, 0.6, 0.07, 0.03]   # silence, overlap(2 speaker), overlap(3 speaker), overlap(4 speaker)
    silence: '1.5-0.5:norm'                      # Gaussian distribution with a mean of 3s and a standard deviation of 2s
    # or silence: '0.10-0.30:unif'   # 5%-15%
    overlap:  
      2: '1-3:unif'         # 0.5s - 3s 
      3: '0.5-1:unif'         # 0.5s - 1s
      4: '0.5-0.8:unif'       # 0.5s - 0.8s

  
  presentation:
    type_weight: 0.5
    main_speaker: '0.2-0.3:0.6-0.7'
    main_speaker_shuffle: 0.1
    interval_ratio: [0.6, 0.3, 0.1]   # silence, overlap(2 speaker), overlap(3 speaker), overlap(4 speaker)
    silence: '1-0.5:norm'        # Gaussian distribution with a mean of 3s and a standard deviation of 2s
    overlap:  
      2: '0.5-1:unif'         # 0.5s - 1s 
      3: '0.5-0.8:unif'       # 0.5s - 0.8s
  
  interview:
    type_weight: 0.5
    interviewer_ratio: '0.15-0.2'
    interval_ratio: [0.6, 0.3, 0.1]  
    silence: '1-0.5:norm'        
    overlap:  
      2: '0.5-1:unif'         # 0.5s - 1s 
      3: '0.5-0.8:unif'       # 0.5s - 0.8s
    

vad_pretrained_model: 'cache/pyannote-vad/pytorch_model.bin'
whisper_model: 'large-v2'
whisper_model_path: 'cache/whisper_model/'
cutting_max_length: 1.5   # (s) max length of each cutting segment


simulate_config:
  point_noise_csv: "config/noise/noise.csv"
  point_noise_type: "config/noise/point_noise.txt"
  fs: 16000 
  rt60:  null
  rt60_mid:  [0.5, 0.8]   # min, max rt60 of middle room
  rt60_lar:  [0.5, 1]     # min, max rt60 of large room
  max_order: null
  room_size:  null
  room_size_mid:  [[8,7,4], [10,8,5]]  # min, max size of middle room(speaker < 20)
  room_size_lar:  [[10,8,4], [12,10,5]]  # min, max size of large room(speaker >= 20)
  room_type:  null    # middle, large
  meeting_type:  null   # desk, circle, speech
  mic_pos: null   # default: middle of the room, height:desk(0.8m-1m) or ceiling
  host_label: null  # set moving host of speech scene
  signal_gains: [1,5] # min, max gain for src_signal
  SNR_point : null
  SNR_point_arr : [2,6]  # min, max snr of point noise
  SNR_diffuse: null
  SNR_diffuse_arr: [3,8]  # min, max snr of diffuse noise
  is_compute_DRR: true   # if compute DRR
  is_compute_SRR: true   # if compute SRR

multi_channel_simulate_config:
  point_noise_csv: "config/noise/noise.csv"
  point_noise_type: "config/noise/point_noise.txt"
  fs: 16000 
  rt60:  null
  rt60_mid:  [0.5, 0.8]   # min, max rt60 of middle room
  rt60_lar:  [0.5, 1]     # min, max rt60 of large room
  max_order: null
  room_size:  null
  room_size_mid:  [[8,7,4], [10,8,5]]  # min, max size of middle room(speaker < 20)
  room_size_lar:  [[10,8,4], [12,10,5]]  # min, max size of large room(speaker >= 20)
  room_type:  null    # middle, large
  meeting_type:  null   # desk, circle, speech
  mic_center_pos: null   # 
  mic_num: null   # mic num of mic array
  mic_num_arr:  [4,6]   # min, max mic num of mic array
  array_num: null   # circle array num, default: 1 in middle room, 2 in large room
  mic_radius: null    # mic radius of circle mic array
  mic_radius_arr:  [0.0425,0.05]    # min, max mic radius of circle mic array
  linear_array_mic_num: 8   # mic num of linear array, default: 8
  linear_array_distances: [0.15,0.1,0.05,0.2,0.05,0.1,0.15]   # intervals for each mic of linear mic array
  host_label: null  # set moving host of speech scene
  signal_gains: [1,5] # min, max gain for src_signal
  SNR_point : null
  SNR_point_arr : [2,6]  # min, max snr of point noise
  SNR_diffuse: null
  SNR_diffuse_arr: [3,8]  # min, max snr of diffuse noise
  is_compute_DRR: true   # if compute DRR
  is_compute_SRR: true   # if compute SRR