
seed: 1234

# speaker logging
iteration: 3000  
max_choose: 10        # max number of each speaker to choose 
stop_available: 10    # stop if the number of available speakers is less than this value
max_examples: 500      # max number of speakers in a meeting

speaker:
  # number: ['1-5:0.1', '6-10:0.2', '11-20:0.5', '21-30:0.2']
  number: ['11-20:0.7', '21-30:0.3']
  gender: ['1:0.15', '0:0.15', '0.5:0.233', '0.4:0.233', '0.6:0.233']   # default 'Male ratio : situation ratio'
  language: ['1:0.33', '0:0.33', 'unif:0.33']                           # default 'English ratio : situation ratio'

utterance: '150-250:unif'
meeting:   
  # Normalize the sampling probability using `type_weight` of all types
  # such as: presentation(0.5), discussion(0.3):
  #   For a sample, there is a probability of 0.5/(0.3+0.5)=0.625 that it is set to type p
  discussion:
    type_weight: 0.5
    interval_ratio: [0.4, 0.5, 0.07, 0.03]   # silence, overlap(2 speaker), overlap(3 speaker), overlap(4 speaker)
    silence: '1.5-0.5:norm'                      # Gaussian distribution with a mean of 3s and a standard deviation of 2s
    # or silence: '0.10-0.30:unif'   # 5%-15%
    overlap:  
      2: '0.5-3:unif'         # 0.5s - 3s 
      3: '0.5-1:unif'         # 0.5s - 1s
      4: '0.5-0.8:unif'       # 0.5s - 0.8s

  
  presentation:
    type_weight: 0.5
    main_speaker: '0.2-0.3:0.6-0.7'
    main_speaker_shuffle: 0.1
    interval_ratio: [0.8, 0.2]   # silence, overlap(2 speaker), overlap(3 speaker), overlap(4 speaker)
    silence: '1-0.5:norm'        # Gaussian distribution with a mean of 3s and a standard deviation of 2s
    overlap:  
      2: '0.5-1:unif'         # 0.5s - 1s 
  
  interview:
    type_weight: 0.5
    interviewer_ratio: '0.15-0.2'
    interval_ratio: [0.8, 0.2]  
    silence: '1-0.5:norm'        
    overlap:  
      2: '0.5-1:unif'         # 0.5s - 1s 
    

vad_pretrained_model: 'cache/pyannote-vad/pytorch_model.bin'
whiper_model: 'large-v2'
cutting_max_length: 1.5   # (s) max length of each cutting segment
